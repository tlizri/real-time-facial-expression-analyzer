{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAKPjcg-mmCV"
      },
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Dropout, Dense, RandomRotation, RandomTranslation, RandomFlip, RandomContrast\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import Input,Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.config import list_physical_devices\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from numpy import load, sum, array\n",
        "from numpy.random import shuffle\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from time import time\n",
        "from numpy import ceil, arange\n",
        "from cv2 import imread, resize, IMREAD_COLOR\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eozPhDWluJs"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
        "CLASSES = 3\n",
        "BATCH_SIZE = 32\n",
        "RED = 'efficientnet'    # vgg16, efficientnet, xception\n",
        "pchs = 40\n",
        "lr=0.001\n",
        "if RED == 'vgg16':\n",
        "    MIN_SIZE = 224\n",
        "elif RED == 'efficientnet':\n",
        "    MIN_SIZE = 224\n",
        "elif RED == 'xception':\n",
        "    MIN_SIZE = 299\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "PATH = '/gdrive' + '/dataset'\n",
        "\n",
        "FILTRAR = 'filt'             # string -> filt, nofilt\n",
        "HOMO = 'balan'                # string -> balan, nobalan\n",
        "\n",
        "class AffectNetSequence(Sequence):\n",
        "    # Clase para realizar una carga de imagenes por lotes debido a la magnitud\n",
        "    # del dataset\n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = arange(len(self.x))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(ceil(len(self.x) / self.batch_size))\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        index = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x = self.x[index]\n",
        "        batch_y = self.y[index]\n",
        "\n",
        "        return array([resize(imread(file_name, IMREAD_COLOR),\n",
        "                                (MIN_SIZE,MIN_SIZE))\n",
        "                                for file_name in batch_x], dtype=float), \\\n",
        "               array(batch_y, dtype = int)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        shuffle(self.indexes)\n",
        "\n",
        "img_augmentation = Sequential(\n",
        "    [\n",
        "        RandomRotation(factor=0.10),\n",
        "        RandomContrast(factor=0.1),\n",
        "    ],\n",
        "    name=\"img_augmentation\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylSv4_PbmdJ-"
      },
      "source": [
        "input = Input(shape=(MIN_SIZE, MIN_SIZE, 3))\n",
        "x = img_augmentation(input)\n",
        "if RED == 'vgg16':\n",
        "    base_model = vgg16(\n",
        "        weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "        input_tensor=x,\n",
        "        include_top=False)\n",
        "\n",
        "elif RED == 'efficientnet':\n",
        "    base_model = EfficientNetB0(\n",
        "        weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "        input_tensor=x,\n",
        "        include_top=False)\n",
        "    \n",
        "elif RED == 'xception':\n",
        "    base_model = Xception(\n",
        "        weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "        input_tensor=x,\n",
        "        include_top=False)\n",
        "elif RED == 'mobilenetv2':\n",
        "    base_model = mobilenetv2(\n",
        "        weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "        input_tensor=x,\n",
        "        include_top=False)\n",
        "    \n",
        "print(range(221))\n",
        "for i in range(221):\n",
        "    base_model.layers[i].trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = BatchNormalization()(x)\n",
        "dropout_rate = 0.2\n",
        "x = Dropout(dropout_rate)(x)\n",
        "output = Dense(CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=input, outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=lr,\n",
        "                              beta_1=0.9,\n",
        "                              beta_2=0.999,\n",
        "                              epsilon=1e-07),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw3yTwC--CR8"
      },
      "source": [
        "x_train = load(PATH + '/x_train_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "x_val = load(PATH + '/x_val_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "y_train = load(PATH + '/y_train_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "y_val = load(PATH + '/y_val_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "y_t = sum(y_train, axis=0)\n",
        "y_v = sum(y_val, axis=0)\n",
        "print(\"Etiquetas de entrenamiento: \" + str(y_t))\n",
        "print(\"Etiquetas de evaluacion: \" + str(y_v))\n",
        "print(\"Imagenes de entrenamiento: \" + str(len(x_train)))\n",
        "print(\"Imagenes de validación: \" + str(len(x_val)))\n",
        "print('Ratio train-val: ' + str(int(100*((len(x_val))/((len(x_train))+(len(x_val)))))) + '%')\n",
        "\n",
        "train_generator = AffectNetSequence(x_train, y_train, BATCH_SIZE)\n",
        "val_generator = AffectNetSequence(x_val, y_val, BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx2AbQDm2_wJ"
      },
      "source": [
        "#Transfer Learning\n",
        "\n",
        "start_time = time()\n",
        "history = model.fit(\n",
        "    x=train_generator,\n",
        "    epochs=pchs,\n",
        "    verbose=1,\n",
        "    validation_data=val_generator,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=int(len(x_train)/BATCH_SIZE),\n",
        "    max_queue_size=8,\n",
        "    workers=4,\n",
        "    use_multiprocessing=True\n",
        "    )\n",
        "end_time = time()\n",
        "execution_time = round((end_time - start_time)/3600, 2)\n",
        "print(str(execution_time))\n",
        "\n",
        "model.save_weights(PATH + '/' + RED + '_learningrate=' + str(lr) + '_' + str(CLASSES) + 'classes_epoch=' + str(pchs) + '_time'+ str(execution_time) + '_' + FILTRAR + '_' + HOMO + '_transfer_learning' + '.h5', save_format=\"h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l2kA_hNAo1F"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'bo', label='Entrenamiento')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validación')\n",
        "plt.title('Precisión de entrenamiento y validación')\n",
        "plt.xlabel(\"Época\")\n",
        "plt.xlabel(\"Precisión\")\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Entrenamiento')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validación')\n",
        "plt.title('Perdidas de entrenamiento y validación')\n",
        "plt.xlabel(\"Época\")\n",
        "plt.xlabel(\"Pérdidas\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}