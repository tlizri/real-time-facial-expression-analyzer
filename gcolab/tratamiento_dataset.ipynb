{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tratamiento_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftnh9xzchPxl"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from pandas import read_csv\n",
        "from numpy import array, concatenate, sum, save, asarray, around\n",
        "from numpy.random import choice\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmt6cB-bhkS9"
      },
      "source": [
        "FILTRAR = 0             # -1 = no filtrar imagenes con MIN_SIZE\n",
        "                         # 0 = filtrar imagenes con MIN_SIZE\n",
        "if FILTRAR == 0:\n",
        "  prop1 = 'filt'\n",
        "else:\n",
        "  prop1 = 'nofilt'\n",
        "\n",
        "BALAN = 0                # -1 = no balancear clases con la misma cantidad de imagenes\n",
        "                        # 0 = balancear clases con la misma cantidad de imagenes\n",
        "if BALAN == 0:\n",
        "  prop2 = 'balan'\n",
        "else:\n",
        "  prop2 = 'nobalan'\n",
        "\n",
        "MIN_SIZE = 299          # 224 para vgg16 y efficientnet\n",
        "                        # 299 xception\n",
        "\n",
        "CLASSES = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OztnbKE4hsKx",
        "outputId": "374278c2-42c9-43af-8537-1a45c75682f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "ROOT = '/gdrive/My Drive'\n",
        "TPATH = '/gdrive/My Drive/AffectNet/Manually_Annotated_Images/training.csv'\n",
        "VPATH = '/gdrive/My Drive/AffectNet/Manually_Annotated_Images/validation.csv'\n",
        "IMG_ROOT = '/gdrive/My Drive/AffectNet/Manually_Annotated_Images'\n",
        "#AUTOMATICALLY_PATH = '/gdrive/My Drive/AffectNet/Automatically_Annotated_Images/automatically_annotated.csv'\n",
        "#AUTOMATICALLY_IMG_ROOT = '/gdrive/My Drive/AffectNet/Automatically_Annotated_Images'\n",
        "AFFECTNET_PATH = '/gdrive/My Drive/AffectNet'\n",
        "PER_VAL = 0.20\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMzKiEyLibwB"
      },
      "source": [
        "def balanceador_clases(x_train, x_val, y_train, y_val):\n",
        "    # Trata de usar la misma cantidad de imagenes/etiquetas\n",
        "    if BALAN == 0:\n",
        "        filenames, labels = concatenar_train_val(x_train, x_val, y_train, y_val)\n",
        "        num_labels = numero_de_imagenes_por_etiqueta(labels)\n",
        "        size = around(min(num_labels), decimals=-3)\n",
        "        new_idx = None\n",
        "        if num_labels[0] > size:\n",
        "            new_idx = choice(asarray(labels == 0).nonzero()[0], size = size)\n",
        "        else:\n",
        "            new_idx = asarray(labels == 0).nonzero()[0]\n",
        "        for i in range(1,CLASSES):\n",
        "            if num_labels[i] > size:\n",
        "                new_idx = concatenate((new_idx, choice(asarray(labels == i).\n",
        "                                                       nonzero()[0], \n",
        "                                                       size = size)))\n",
        "            else:\n",
        "                new_idx = concatenate((new_idx, asarray(labels == i).\n",
        "                                       nonzero()[0]))\n",
        "                \n",
        "        filenames_shuffled, labels_shuffled = shuffle(filenames[new_idx], labels[new_idx])\n",
        "        x_train, x_val, y_train, y_val = train_test_split(filenames_shuffled, labels_shuffled, test_size=PER_VAL)\n",
        "        return x_train, x_val, y_train, y_val\n",
        "    else:\n",
        "        filenames, labels = concatenar_train_val(x_train, x_val, y_train, y_val)\n",
        "        filenames_shuffled, labels_shuffled = shuffle(filenames, labels)\n",
        "        x_train, x_val, y_train, y_val = train_test_split(filenames_shuffled, labels_shuffled, test_size=PER_VAL)\n",
        "        return x_train, x_val, y_train, y_val\n",
        "\n",
        "def leer_CSV():\n",
        "    raw_train = read_csv(TPATH, header = 0, names = array(['file_path', \n",
        "                                                           'face_x',\n",
        "                                                           'face_y', \n",
        "                                                           'face_width',\n",
        "                                                           'face_height', \n",
        "                                                           'facial_landmarks',\n",
        "                                                           'expression', \n",
        "                                                           'valence',\n",
        "                                                           'arousal']))\n",
        "    raw_val = read_csv(VPATH, header=None, names = array(['file_path',\n",
        "                                                          'face_x',\n",
        "                                                          'face_y',\n",
        "                                                          'face_width',\n",
        "                                                          'face_height',\n",
        "                                                          'facial_landmarks',\n",
        "                                                          'expression',\n",
        "                                                          'valence',\n",
        "                                                          'arousal']))\n",
        "    train_dir = raw_train['file_path']\n",
        "    train_dir = IMG_ROOT + '/' + train_dir\n",
        "    val_dir = raw_val['file_path']\n",
        "    val_dir = IMG_ROOT + '/' + val_dir\n",
        "    train_width = raw_train['face_width']\n",
        "    train_height = raw_train['face_height']\n",
        "    val_width = raw_val['face_width']\n",
        "    val_height = raw_val['face_height']\n",
        "    labels_train = raw_train['expression']\n",
        "    labels_val = raw_val['expression']\n",
        "    return train_dir, val_dir, train_width, train_height, val_width, \\\n",
        "           val_height, labels_train, labels_val\n",
        "\n",
        "def filtrado(train_dir, train_height, labels_train, val_dir, labels_val, \n",
        "             val_height):\n",
        "    # Descartamos las imagenes que no tienen un minimo de tamaño necesario para el entrenamiento\n",
        "    # Debe ir despues de leer el archivo CSV\n",
        "    if FILTRAR == 0:\n",
        "        x_train = train_dir[train_height >= MIN_SIZE].to_numpy(dtype=str)\n",
        "        y_train = labels_train[train_height >= MIN_SIZE].to_numpy(dtype='uint8')\n",
        "        x_val = val_dir[val_height >= MIN_SIZE].to_numpy(dtype=str)\n",
        "        y_val = labels_val[val_height >= MIN_SIZE].to_numpy(dtype='uint8')\n",
        "        filenames, labels = concatenar_train_val(x_train, x_val, y_train, y_val)\n",
        "        filenames_shuffled, labels_shuffled = shuffle(filenames, labels)\n",
        "        x_train, x_val, y_train, y_val = train_test_split(filenames_shuffled, labels_shuffled, test_size=PER_VAL)\n",
        "        return x_train, x_val, y_train, y_val\n",
        "    else:\n",
        "        filenames, labels = concatenar_train_val(train_dir, val_dir, labels_train, labels_val)\n",
        "        filenames_shuffled, labels_shuffled = shuffle(filenames, labels)\n",
        "        x_train, x_val, y_train, y_val = train_test_split(filenames_shuffled, labels_shuffled, test_size=PER_VAL)\n",
        "        return x_train, x_val, y_train, y_val\n",
        "\n",
        "def es_cuadrado(train_width, train_height, val_width, val_height):\n",
        "    # Comprobamos si el dataset tiene las imagenes cuadradas\n",
        "    if any(train_width != train_height):\n",
        "        return False\n",
        "    elif any(val_width != val_height):\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def concatenar_train_val(x_train, x_val, y_train, y_val):\n",
        "    # Unimos los datos de entrenamiento y validacion en un mismo array\n",
        "    return concatenate((x_train, x_val), axis=0), concatenate((y_train, \n",
        "                                                               y_val), axis=0)\n",
        "\n",
        "def numero_de_imagenes_por_etiqueta(labels):\n",
        "    # Cuenta el numero de imagenes/etiqueta\n",
        "    return sum(to_categorical(labels, num_classes = CLASSES, dtype = 'uint32'), \n",
        "               axis=0)\n",
        "\n",
        "def save_generate_train_val_sets(x_train, x_val, y_train, y_val):\n",
        "    # Generamos archivos con los datos para entrenar y validar\n",
        "    # Devuelve las rutas y etiquetas para entrenamiento y validación\n",
        "\n",
        "    save(AFFECTNET_PATH + '/x_train_data_' + str(CLASSES) + 'classes_' + prop1 + '_' + prop2 + '_size=' + str(MIN_SIZE) + '.npy', x_train)\n",
        "    save(AFFECTNET_PATH + '/x_val_data_' + str(CLASSES) + 'classes_' + prop1 + '_' + prop2 + '_size=' + str(MIN_SIZE) + '.npy', x_val)\n",
        "    save(AFFECTNET_PATH + '/y_train_data_' + str(CLASSES) + 'classes_' + prop1 + '_' + prop2 + '_size=' + str(MIN_SIZE) + '.npy', to_categorical(y_train, num_classes = CLASSES, dtype = 'uint8'))\n",
        "    save(AFFECTNET_PATH + '/y_val_data_' + str(CLASSES) + 'classes_' + prop1 + '_' + prop2 + '_size=' + str(MIN_SIZE) + '.npy', to_categorical(y_val, num_classes = CLASSES, dtype = 'uint8'))\n",
        "    \n",
        "    return x_train, x_val, to_categorical(y_train, num_classes = CLASSES, dtype = 'uint8'), to_categorical(y_val, num_classes = CLASSES, dtype = 'uint8')\n",
        "\n",
        "def despreciar_clases(x_train, x_val, y_train, y_val):\n",
        "    if CLASSES == 3:\n",
        "        indice_train = ((y_train == 0) | (y_train == 1) | (y_train == 2) | (y_train == 3)| (y_train == 4)| (y_train == 5)| (y_train == 6)| (y_train == 7))\n",
        "        indice_val = ((y_val == 0) | (y_val == 1) | (y_val == 2) | (y_val == 3)| (y_val == 4)| (y_val == 5)| (y_val == 6)| (y_val == 7))\n",
        "        \n",
        "        positive_train_idx = ((y_train == 1) | (y_train == 3))\n",
        "        negative_train_idx = ((y_train == 2) | (y_train == 4) | (y_train == 5) | (y_train == 6) | (y_train == 7))\n",
        "        neutral_train_idx = (y_train == 0)\n",
        "\n",
        "        positive_val_idx = ((y_val == 1) | (y_val == 3))\n",
        "        negative_val_idx = ((y_val == 2) | (y_val == 4) | (y_val == 5) | (y_val == 6) | (y_val == 7))\n",
        "        neutral_val_idx = (y_val == 0)\n",
        "\n",
        "        y_train[positive_train_idx] = 0\n",
        "        y_train[negative_train_idx] = 1\n",
        "        y_train[neutral_train_idx] = 2\n",
        "\n",
        "        y_val[positive_val_idx] = 0\n",
        "        y_val[negative_val_idx] = 1\n",
        "        y_val[neutral_val_idx] = 2\n",
        "    if CLASSES == 2:\n",
        "        indice_train = ((y_train == 1) | (y_train == 2))\n",
        "        indice_val = ((y_val == 1) | (y_val == 2))\n",
        "        \n",
        "        positive_train_idx = (y_train == 1)\n",
        "        negative_train_idx = (y_train == 2)\n",
        "\n",
        "        positive_val_idx = (y_val == 1)\n",
        "        negative_val_idx = (y_val == 2)\n",
        "\n",
        "        y_train[positive_train_idx] = 0\n",
        "        y_train[negative_train_idx] = 1\n",
        "\n",
        "        y_val[positive_val_idx] = 0\n",
        "        y_val[negative_val_idx] = 1\n",
        "\n",
        "    return x_train[indice_train], x_val[indice_val], y_train[indice_train], y_val[indice_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv8NXOMcjHeB",
        "outputId": "7e54bc43-83de-4505-9bae-97d89ccf9e26"
      },
      "source": [
        "print('Cargando CSV')\n",
        "train_dir, val_dir, train_width, train_height, val_width, val_height, \\\n",
        "                                        labels_train, labels_val = leer_CSV()\n",
        "if es_cuadrado(train_width, train_height, val_width, val_height):\n",
        "    print('Imagenes cuadradas')\n",
        "else:\n",
        "    print('Imagenes no cuadradas')\n",
        "\n",
        "print('Filtrado')\n",
        "x_train, x_val, y_train, y_val = filtrado(train_dir, train_height, \n",
        "                                          labels_train, val_dir, \n",
        "                                          labels_val, val_height)\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = despreciar_clases(x_train, x_val, y_train, y_val)\n",
        "x_train, x_val, y_train, y_val = balanceador_clases(x_train, x_val, y_train, y_val)\n",
        "\n",
        "print('Guardando...')\n",
        "print(\"Imagenes por etiquetas: \")\n",
        "print(numero_de_imagenes_por_etiqueta(concatenate((y_train, y_val), axis=0)))\n",
        "print(\"Imagenes de entrenamiento: \" + str(len(x_train)))\n",
        "print(\"Imagenes de validación: \" + str(len(x_val)))\n",
        "x_train, x_val, y_train, y_val = save_generate_train_val_sets(x_train, x_val, y_train, y_val)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cargando CSV\n",
            "Imagenes cuadradas\n",
            "Filtrado\n",
            "Guardando...\n",
            "Imagenes por etiquetas: \n",
            "[32000 31676 32000]\n",
            "Imagenes de entrenamiento: 76540\n",
            "Imagenes de validación: 19136\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}