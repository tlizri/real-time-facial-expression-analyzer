{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNLeReB8sjov"
      },
      "source": [
        "from tensorflow.config import list_physical_devices\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from numpy import arange\n",
        "from numpy.random import shuffle\n",
        "from math import ceil\n",
        "from cv2 import imread, resize, IMREAD_COLOR\n",
        "from numpy import array, load, sum\n",
        "from keras import Model\n",
        "from tensorflow.keras.applications import VGG16, EfficientNetB0, Xception, MobileNetV2\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgA_LjP5ssNJ",
        "outputId": "fc998226-917b-46ac-f6c3-721f9454d715"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
        "\n",
        "CLASSES = 3\n",
        "BATCH_SIZE = 32\n",
        "RED = 'efficientnet'    # vgg16, efficientnet, xception\n",
        "pchs = 9\n",
        "lr=0.001\n",
        "if RED == 'vgg16':\n",
        "    MIN_SIZE = 224\n",
        "elif RED == 'efficientnet':\n",
        "    MIN_SIZE = 224\n",
        "elif RED == 'xception':\n",
        "    MIN_SIZE = 299\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "PATH = '/gdrive' + '/Path to dataset'\n",
        "\n",
        "FILTRAR = 'filt'             # string -> filt, nofilt\n",
        "HOMO = 'balan'                # string -> balan, nobalan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k87z8tDjstFp"
      },
      "source": [
        "class AffectNetSequence(Sequence):\n",
        "    # Clase para realizar una carga de imagenes por lotes debido a la magnitud\n",
        "    # del dataset\n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = arange(len(self.x))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(ceil(len(self.x) / self.batch_size))\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        index = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x = self.x[index]\n",
        "        batch_y = self.y[index]\n",
        "\n",
        "        return array([resize(imread(file_name, IMREAD_COLOR),\n",
        "                                (MIN_SIZE,MIN_SIZE))/255.0\n",
        "                                for file_name in batch_x], dtype=float), \\\n",
        "               array(batch_y, dtype = int)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        shuffle(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "3cZJ_mNKswOZ",
        "outputId": "d071bcd5-7ec9-4992-ae6e-23c4988fa8e6"
      },
      "source": [
        "x_train = load(PATH + '/x_train_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "x_val = load(PATH + '/x_val_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "y_train = load(PATH + '/y_train_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "y_val = load(PATH + '/y_val_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "y_t = sum(y_train, axis=0)\n",
        "y_v = sum(y_val, axis=0)\n",
        "print(\"Etiquetas de entrenamiento: \" + str(y_t))\n",
        "print(\"Etiquetas de evaluacion: \" + str(y_v))\n",
        "print(\"Imagenes de entrenamiento: \" + str(len(x_train)))\n",
        "print(\"Imagenes de validación: \" + str(len(x_val)))\n",
        "print('Ratio train-val: ' + str(int(100*((len(x_val))/((len(x_train))+(len(x_val)))))) + '%')\n",
        "\n",
        "train_generator = AffectNetSequence(x_train, y_train, BATCH_SIZE)\n",
        "val_generator = AffectNetSequence(x_val, y_val, BATCH_SIZE)\n",
        "\n",
        "if RED == 'vgg16':\n",
        "    model = VGG16(\n",
        "                  include_top=True,\n",
        "                  weights=None,\n",
        "                  classes=CLASSES,\n",
        "                  classifier_activation=\"softmax\")\n",
        "\n",
        "elif RED == 'efficientnet':\n",
        "    model = EfficientNetB0(\n",
        "                            include_top=True,\n",
        "                            weights=None,\n",
        "                            classes=CLASSES,\n",
        "                            classifier_activation=\"softmax\")\n",
        "    \n",
        "elif RED == 'xception':\n",
        "    model = Xception(\n",
        "                    include_top=True,\n",
        "                    weights=None,\n",
        "                    classes=CLASSES,\n",
        "                    classifier_activation=\"softmax\")\n",
        "elif RED == 'mobilenetv2':\n",
        "    model = MobileNetV2(\n",
        "                        include_top=True,\n",
        "                        weights=None,\n",
        "                        classes=CLASSES,\n",
        "                        classifier_activation=\"softmax\")\n",
        "    \n",
        "model.compile(optimizer=Adam(learning_rate=lr,\n",
        "                              beta_1=0.9,\n",
        "                              beta_2=0.999,\n",
        "                              epsilon=1e-07),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "start_time = time()\n",
        "history = model.fit(\n",
        "    x=train_generator,\n",
        "    epochs=pchs,\n",
        "    verbose=1,\n",
        "    validation_data=val_generator,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=(ceil(len(x_train) / BATCH_SIZE)),\n",
        "    max_queue_size=8,\n",
        "    workers=4,\n",
        "    use_multiprocessing=True\n",
        "    )\n",
        "end_time = time()\n",
        "execution_time = round((end_time - start_time)/3600, 2)\n",
        "print(str(execution_time))\n",
        "\n",
        "model.save(PATH + '/' + RED + '_learningrate=' + str(lr) + '_' + str(CLASSES) + 'classes_epoch=' + str(pchs) + '_time'+ str(execution_time) + '_' + FILTRAR + '_' + HOMO + '.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnh5KFVrTo79"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'bo', label='Entrenamiento')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validación')\n",
        "plt.title('Precisión de entrenamiento y validación')\n",
        "plt.ylabel(\"Pasadas\")\n",
        "plt.xlabel(\"Precisión\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Entrenamiento')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validación')\n",
        "plt.title('Perdidas de entrenamiento y validación')\n",
        "plt.ylabel(\"Pasadas\")\n",
        "plt.xlabel(\"Pérdidas\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgA_LjP5ssNJ",
        "outputId": "fc998226-917b-46ac-f6c3-721f9454d715"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
        "\n",
        "CLASSES = 3\n",
        "BATCH_SIZE = 32\n",
        "RED = 'efficientnet'    # vgg16, efficientnet, xception\n",
        "pchs = 9\n",
        "lr=0.001\n",
        "if RED == 'vgg16':\n",
        "    MIN_SIZE = 224\n",
        "elif RED == 'efficientnet':\n",
        "    MIN_SIZE = 224\n",
        "elif RED == 'xception':\n",
        "    MIN_SIZE = 299\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "PATH = '/gdrive' + '/Path to dataset'\n",
        "\n",
        "FILTRAR = 'filt'             # string -> filt, nofilt\n",
        "HOMO = 'balan'                # string -> balan, nobalan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k87z8tDjstFp"
      },
      "source": [
        "class AffectNetSequence(Sequence):\n",
        "    # Clase para realizar una carga de imagenes por lotes debido a la magnitud\n",
        "    # del dataset\n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = arange(len(self.x))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(ceil(len(self.x) / self.batch_size))\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        index = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x = self.x[index]\n",
        "        batch_y = self.y[index]\n",
        "\n",
        "        return array([resize(imread(file_name, IMREAD_COLOR),\n",
        "                                (MIN_SIZE,MIN_SIZE))/255.0\n",
        "                                for file_name in batch_x], dtype=float), \\\n",
        "               array(batch_y, dtype = int)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        shuffle(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "3cZJ_mNKswOZ",
        "outputId": "d071bcd5-7ec9-4992-ae6e-23c4988fa8e6"
      },
      "source": [
        "x_train = load(PATH + '/x_train_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "x_val = load(PATH + '/x_val_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "y_train = load(PATH + '/y_train_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "y_val = load(PATH + '/y_val_data_' + str(CLASSES) + 'classes_' + FILTRAR + '_' + HOMO + '_' + 'size=' + str(MIN_SIZE) + '.npy', allow_pickle=True)\n",
        "y_t = sum(y_train, axis=0)\n",
        "y_v = sum(y_val, axis=0)\n",
        "print(\"Etiquetas de entrenamiento: \" + str(y_t))\n",
        "print(\"Etiquetas de evaluacion: \" + str(y_v))\n",
        "print(\"Imagenes de entrenamiento: \" + str(len(x_train)))\n",
        "print(\"Imagenes de validación: \" + str(len(x_val)))\n",
        "print('Ratio train-val: ' + str(int(100*((len(x_val))/((len(x_train))+(len(x_val)))))) + '%')\n",
        "\n",
        "train_generator = AffectNetSequence(x_train, y_train, BATCH_SIZE)\n",
        "val_generator = AffectNetSequence(x_val, y_val, BATCH_SIZE)\n",
        "\n",
        "if RED == 'vgg16':\n",
        "    model = VGG16(\n",
        "                  include_top=True,\n",
        "                  weights=None,\n",
        "                  classes=CLASSES,\n",
        "                  classifier_activation=\"softmax\")\n",
        "\n",
        "elif RED == 'efficientnet':\n",
        "    model = EfficientNetB0(\n",
        "                            include_top=True,\n",
        "                            weights=None,\n",
        "                            classes=CLASSES,\n",
        "                            classifier_activation=\"softmax\")\n",
        "    \n",
        "elif RED == 'xception':\n",
        "    model = Xception(\n",
        "                    include_top=True,\n",
        "                    weights=None,\n",
        "                    classes=CLASSES,\n",
        "                    classifier_activation=\"softmax\")\n",
        "elif RED == 'mobilenetv2':\n",
        "    model = MobileNetV2(\n",
        "                        include_top=True,\n",
        "                        weights=None,\n",
        "                        classes=CLASSES,\n",
        "                        classifier_activation=\"softmax\")\n",
        "    \n",
        "model.compile(optimizer=Adam(learning_rate=lr,\n",
        "                              beta_1=0.9,\n",
        "                              beta_2=0.999,\n",
        "                              epsilon=1e-07),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "start_time = time()\n",
        "history = model.fit(\n",
        "    x=train_generator,\n",
        "    epochs=pchs,\n",
        "    verbose=1,\n",
        "    validation_data=val_generator,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=(ceil(len(x_train) / BATCH_SIZE)),\n",
        "    max_queue_size=8,\n",
        "    workers=4,\n",
        "    use_multiprocessing=True\n",
        "    )\n",
        "end_time = time()\n",
        "execution_time = round((end_time - start_time)/3600, 2)\n",
        "print(str(execution_time))\n",
        "\n",
        "model.save(PATH + '/' + RED + '_learningrate=' + str(lr) + '_' + str(CLASSES) + 'classes_epoch=' + str(pchs) + '_time'+ str(execution_time) + '_' + FILTRAR + '_' + HOMO + '.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas de entrenamiento: [34386 34406 34408]\n",
            "Etiquetas de evaluacion: [8614 8594 8592]\n",
            "Imagenes de entrenamiento: 103200\n",
            "Imagenes de validación: 25800\n",
            "Ratio train-val: 20%\n"
          ]
        },
      "execution_count": null,
      "outputs": []
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnh5KFVrTo79"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'bo', label='Entrenamiento')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validación')\n",
        "plt.title('Precisión de entrenamiento y validación')\n",
        "plt.ylabel(\"Pasadas\")\n",
        "plt.xlabel(\"Precisión\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Entrenamiento')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validación')\n",
        "plt.title('Perdidas de entrenamiento y validación')\n",
        "plt.ylabel(\"Pasadas\")\n",
        "plt.xlabel(\"Pérdidas\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
